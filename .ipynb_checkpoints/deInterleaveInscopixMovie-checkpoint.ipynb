{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0943c78b-1b56-4dde-9613-5a407c7dc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d664d323-4adb-4322-80aa-595bc1bfe0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names and dataset name\n",
    "dirPath = '/Users/johnmarshall/Documents/Analysis/nVueData/SPRT/SPRT_m1_d6/'\n",
    "input_file = 'concat_inscopix-1_2024-11-12-15-23-47_video_multiplexing_trig_0.h5'\n",
    "dataset_name = '/1'\n",
    "output_file_ch1 = '2024-11-12-15-23-47_channel1.h5'\n",
    "output_file_ch2 = '2024-11-12-15-23-47_channel2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3c149b-4b07-4eb8-adab-9c7b0c83af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a chunk size for processing (tweak this based on your available RAM)\n",
    "chunk_size = 100  # number of frames to process per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c9fac8-5836-4157-b917-ddebf202839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frames 0 to 100 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 100 to 200 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 200 to 300 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 300 to 400 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 400 to 500 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 500 to 600 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 600 to 700 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 700 to 800 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 800 to 900 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 900 to 1000 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1000 to 1100 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1100 to 1200 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1200 to 1300 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1300 to 1400 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1400 to 1500 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1500 to 1600 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1600 to 1700 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1700 to 1800 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1800 to 1900 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 1900 to 2000 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2000 to 2100 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2100 to 2200 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2200 to 2300 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2300 to 2400 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2400 to 2500 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2500 to 2600 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2600 to 2700 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2700 to 2800 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2800 to 2900 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 2900 to 3000 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3000 to 3100 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3100 to 3200 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3200 to 3300 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3300 to 3400 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3400 to 3500 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3500 to 3600 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3600 to 3700 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3700 to 3800 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3800 to 3900 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 3900 to 4000 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4000 to 4100 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4100 to 4200 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4200 to 4300 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4300 to 4400 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4400 to 4500 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4500 to 4600 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4600 to 4700 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4700 to 4800 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4800 to 4900 (ch1: 50 frames, ch2: 50 frames)\n",
      "Processed frames 4900 to 5000 (ch1: 50 frames, ch2: 50 frames)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Write through page buffer failed (file write failed: time = Mon Mar 10 16:20:57 2025\n, filename = '/Users/johnmarshall/Documents/Analysis/nVueData/SPRT/SPRT_m1_d6/2024-11-12-15-23-47_channel1.h5', file descriptor = 75, errno = 28, error message = 'No space left on device', buf = 0x1781c0008, total write size = 202000, bytes this sub-write = 202000, offset = 5308015320)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     30\u001b[0m n_ch2 \u001b[38;5;241m=\u001b[39m ch2_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m dset_ch1[idx_ch1:idx_ch1\u001b[38;5;241m+\u001b[39mn_ch1, :, :] \u001b[38;5;241m=\u001b[39m ch1_chunk\n\u001b[1;32m     32\u001b[0m dset_ch2[idx_ch2:idx_ch2\u001b[38;5;241m+\u001b[39mn_ch2, :, :] \u001b[38;5;241m=\u001b[39m ch2_chunk \n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/miniscopeAnalysisEnv/lib/python3.13/site-packages/h5py/_hl/dataset.py:1022\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fspace \u001b[38;5;129;01min\u001b[39;00m selection\u001b[38;5;241m.\u001b[39mbroadcast(mshape):\n\u001b[0;32m-> 1022\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mwrite(mspace, fspace, val, mtype, dxpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dxpl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:281\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_proxy.pyx:115\u001b[0m, in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] Can't synchronously write data (file write failed: time = Mon Mar 10 16:20:55 2025\n, filename = '/Users/johnmarshall/Documents/Analysis/nVueData/SPRT/SPRT_m1_d6/2024-11-12-15-23-47_channel1.h5', file descriptor = 75, errno = 28, error message = 'No space left on device', buf = 0x1182e0008, total write size = 202000, bytes this sub-write = 202000, offset = 5307813320)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create output files and datasets for each channel.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(dirPath\u001b[38;5;241m+\u001b[39moutput_file_ch1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_ch1, h5py\u001b[38;5;241m.\u001b[39mFile(dirPath\u001b[38;5;241m+\u001b[39moutput_file_ch2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_ch2:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Create datasets with the appropriate shape and same dtype\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     dset_ch1 \u001b[38;5;241m=\u001b[39m f_ch1\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m(nframes_ch1, height, width), dtype\u001b[38;5;241m=\u001b[39mdset\u001b[38;5;241m.\u001b[39mdtype, chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/miniscopeAnalysisEnv/lib/python3.13/site-packages/h5py/_hl/files.py:598\u001b[0m, in \u001b[0;36mFile.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/miniscopeAnalysisEnv/lib/python3.13/site-packages/h5py/_hl/files.py:580\u001b[0m, in \u001b[0;36mFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m \u001b[38;5;241m~\u001b[39mh5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m h5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:355\u001b[0m, in \u001b[0;36mh5py.h5f.FileID._close_open_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Disable slist on flush dest failure failed (file write failed: time = Mon Mar 10 16:20:55 2025\n, filename = '/Users/johnmarshall/Documents/Analysis/nVueData/SPRT/SPRT_m1_d6/2024-11-12-15-23-47_channel2.h5', file descriptor = 76, errno = 28, error message = 'No space left on device', buf = 0x1059e9a08, total write size = 6272, bytes this sub-write = 6272, offset = 4021119816)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m nframes_ch2 \u001b[38;5;241m=\u001b[39m total_frames \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create output files and datasets for each channel.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(dirPath\u001b[38;5;241m+\u001b[39moutput_file_ch1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_ch1, h5py\u001b[38;5;241m.\u001b[39mFile(dirPath\u001b[38;5;241m+\u001b[39moutput_file_ch2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_ch2:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Create datasets with the appropriate shape and same dtype\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     dset_ch1 \u001b[38;5;241m=\u001b[39m f_ch1\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m(nframes_ch1, height, width), dtype\u001b[38;5;241m=\u001b[39mdset\u001b[38;5;241m.\u001b[39mdtype, chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     dset_ch2 \u001b[38;5;241m=\u001b[39m f_ch2\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m(nframes_ch2, height, width), dtype\u001b[38;5;241m=\u001b[39mdset\u001b[38;5;241m.\u001b[39mdtype, chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)      \n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/miniscopeAnalysisEnv/lib/python3.13/site-packages/h5py/_hl/files.py:598\u001b[0m, in \u001b[0;36mFile.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid:\n\u001b[0;32m--> 598\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/miniscopeAnalysisEnv/lib/python3.13/site-packages/h5py/_hl/files.py:579\u001b[0m, in \u001b[0;36mFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m phil:\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# Check that the file is still open, otherwise skip\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mvalid:\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;66;03m# We have to explicitly murder all open objects related to the file\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \n\u001b[1;32m    577\u001b[0m         \u001b[38;5;66;03m# Close file-resident objects first, then the files.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;66;03m# Otherwise we get errors in MPI mode.\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m \u001b[38;5;241m~\u001b[39mh5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m h5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:355\u001b[0m, in \u001b[0;36mh5py.h5f.FileID._close_open_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] Write through page buffer failed (file write failed: time = Mon Mar 10 16:20:57 2025\n, filename = '/Users/johnmarshall/Documents/Analysis/nVueData/SPRT/SPRT_m1_d6/2024-11-12-15-23-47_channel1.h5', file descriptor = 75, errno = 28, error message = 'No space left on device', buf = 0x1781c0008, total write size = 202000, bytes this sub-write = 202000, offset = 5308015320)"
     ]
    }
   ],
   "source": [
    "# Open the original file in read-only mode\n",
    "with h5py.File(dirPath+input_file, 'r') as f_in:\n",
    "    dset = f_in[dataset_name]\n",
    "    total_frames, height, width = dset.shape\n",
    "    # Determine the number of frames for each channel.\n",
    "    # Even-numbered frames (0,2,4,...) go to channel 1.\n",
    "    # Odd-numbered frames (1,3,5,...) go to channel 2.\n",
    "    nframes_ch1 = total_frames // 2 + total_frames % 2\n",
    "    nframes_ch2 = total_frames // 2\n",
    "    # Create output files and datasets for each channel.\n",
    "    with h5py.File(dirPath+output_file_ch1, 'w') as f_ch1, h5py.File(dirPath+output_file_ch2, 'w') as f_ch2:\n",
    "        # Create datasets with the appropriate shape and same dtype\n",
    "        dset_ch1 = f_ch1.create_dataset('data', shape=(nframes_ch1, height, width), dtype=dset.dtype, chunks=True)\n",
    "        dset_ch2 = f_ch2.create_dataset('data', shape=(nframes_ch2, height, width), dtype=dset.dtype, chunks=True)      \n",
    "        # Initialize write indices for each channel\n",
    "        idx_ch1 = 0\n",
    "        idx_ch2 = 0\n",
    "        # Process the dataset in chunks along the first dimension\n",
    "        for start in range(0, total_frames, chunk_size):\n",
    "            end = min(start + chunk_size, total_frames)\n",
    "            # Read a chunk from the original dataset\n",
    "            chunk = dset[start:end, :, :]            \n",
    "            # Deinterleave the frames:\n",
    "            # Channel 1 gets even-indexed frames within the chunk\n",
    "            ch1_chunk = chunk[0:(end - start):2]\n",
    "            # Channel 2 gets odd-indexed frames within the chunk\n",
    "            ch2_chunk = chunk[1:(end - start):2]\n",
    "            # Write the chunks to the corresponding datasets\n",
    "            n_ch1 = ch1_chunk.shape[0]\n",
    "            n_ch2 = ch2_chunk.shape[0]\n",
    "            dset_ch1[idx_ch1:idx_ch1+n_ch1, :, :] = ch1_chunk\n",
    "            dset_ch2[idx_ch2:idx_ch2+n_ch2, :, :] = ch2_chunk \n",
    "            # Update indices for next write position\n",
    "            idx_ch1 += n_ch1\n",
    "            idx_ch2 += n_ch2  \n",
    "            print(f\"Processed frames {start} to {end} (ch1: {n_ch1} frames, ch2: {n_ch2} frames)\")\n",
    "print(\"Deinterleaving complete. Two files have been created for channel 1 and channel 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e66b4-7016-4650-9300-c28a7cec9874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniscopeAnalysisEnv",
   "language": "python",
   "name": "miniscopeanalysisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
